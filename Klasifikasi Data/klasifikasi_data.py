# -*- coding: utf-8 -*-
"""klasifikasi data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11_xU2poFPd1OieJe_6LW1galMQSzaCYn
"""

# ============================================================
# IMPORT LIBRARY & KONFIGURASI
# ============================================================

!pip install gensim
!pip install Sastrawi

import pandas as pd
import numpy as np
import re
import string
from collections import Counter

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC

# Untuk Word2Vec + LSTM (dipakai di percobaan 4)
from gensim.models import Word2Vec
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder

# Stemming Bahasa Indonesia (Sastrawi)
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

RANDOM_STATE = 42
CSV_PATH = "data_manual_250.csv"

# ============================================================
# PREPROCESSING (STEEMING + "LEMMATISASI")
# ============================================================

factory = StemmerFactory()
stemmer = factory.create_stemmer()

# Kamus lemmatisasi sederhana (bisa kamu tambah sendiri)
LEMMATIZATION_DICT = {
    "nggak": "tidak",
    "gak": "tidak",
    "ga": "tidak",
    "ngga": "tidak",
    "bgt": "banget",
    "bener": "benar",
    "beneran": "benar",
}

def basic_clean(text: str) -> str:
    """Lowercase, hilangkan angka & punctuation, normalisasi spasi."""
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+", " ", text)       # hapus URL
    text = re.sub(r"\d+", " ", text)                  # hapus angka
    text = text.translate(str.maketrans("", "", string.punctuation))  # hapus tanda baca
    text = re.sub(r"\s+", " ", text).strip()
    return text

def apply_lemmatization(tokens):
    """Mapping token berdasarkan kamus lemmatisasi sederhana."""
    return [LEMMATIZATION_DICT.get(tok, tok) for tok in tokens]

def preprocess_text(text: str) -> str:
    """
    Pipeline preprocessing:
    1) basic cleaning
    2) stemming Sastrawi
    3) lemmatisasi kamus sederhana
    """
    cleaned = basic_clean(text)
    stemmed = stemmer.stem(cleaned)
    tokens = stemmed.split()
    tokens = apply_lemmatization(tokens)
    return " ".join(tokens)

# ============================================================
# LOAD DATA & TRAIN-TEST SPLIT
# ============================================================

df = pd.read_csv(CSV_PATH)
print(df.head())
print(df["label"].value_counts())

texts_raw = df["cleaned"].astype(str)
labels_raw = df["label"].astype(str)

print("\n[INFO] Melakukan preprocessing (stem + lemmatization)...")
texts_processed = texts_raw.apply(preprocess_text)

X_train, X_test, y_train, y_test = train_test_split(
    texts_processed,
    labels_raw,
    test_size=0.2,
    random_state=RANDOM_STATE,
    stratify=labels_raw
)

print("[INFO] Distribusi label train:", Counter(y_train))
print("[INFO] Distribusi label test :", Counter(y_test))

# ============================================================
# PERCOBAAN 1 - BOW + LOGISTIC REGRESSION
# ============================================================

bow_vectorizer_6 = CountVectorizer(
    max_features=5000,
    ngram_range=(1, 1)
)

X_train_bow_6 = bow_vectorizer_6.fit_transform(X_train)
X_test_bow_6 = bow_vectorizer_6.transform(X_test)

logreg_bow_clf = LogisticRegression(
    max_iter=1000,
    multi_class="multinomial",
    solver="lbfgs",
    random_state=RANDOM_STATE
)
logreg_bow_clf.fit(X_train_bow_6, y_train)

y_pred_logreg_bow = logreg_bow_clf.predict(X_test_bow_6)

print("=== Percobaan 1: BoW + Logistic Regression ===")
print("Accuracy:", accuracy_score(y_test, y_pred_logreg_bow))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_logreg_bow, digits=4))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_logreg_bow))

# ============================================================
# PERCOBAAN 2 - TF-IDF KARAKTER + LINEAR SVM
# ============================================================

from sklearn.feature_extraction.text import TfidfVectorizer as CharTfidfVectorizer

char_tfidf_vectorizer = CharTfidfVectorizer(
    analyzer="char",
    ngram_range=(3, 5),   # character 3–5-gram
    max_features=8000
)

X_train_char = char_tfidf_vectorizer.fit_transform(X_train)
X_test_char = char_tfidf_vectorizer.transform(X_test)

svm_char_clf = LinearSVC(random_state=RANDOM_STATE)
svm_char_clf.fit(X_train_char, y_train)

y_pred_char_svm = svm_char_clf.predict(X_test_char)

print("=== Percobaan 2: TF-IDF Karakter (3–5-gram) + Linear SVM ===")
print("Accuracy:", accuracy_score(y_test, y_pred_char_svm))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_char_svm, digits=4))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_char_svm))

# ============================================================
# PERCOBAAN 3: BoW (1–2 gram) + Linear SVM
# ============================================================

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

bow_1_2_vec = CountVectorizer(
    max_features=7000,
    ngram_range=(1, 2)   # unigram + bigram
)

X_train_bow_1_2 = bow_1_2_vec.fit_transform(X_train)
X_test_bow_1_2  = bow_1_2_vec.transform(X_test)

svm_bow = LinearSVC(
    C=1.0,
    random_state=RANDOM_STATE
)
svm_bow.fit(X_train_bow_1_2, y_train)

y_pred_bow_svm = svm_bow.predict(X_test_bow_1_2)

print("=== Percobaan 3: BoW (1–2 gram) + Linear SVM ===")
print("Accuracy:", accuracy_score(y_test, y_pred_bow_svm))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_bow_svm, digits=4))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_bow_svm))

pip install sentence-transformers

# ============================================================
# PERCOBAAN 4 - TRANSFORMER (SBERT) + LINEAR SVM
# ============================================================

from sentence_transformers import SentenceTransformer

sbert_model = SentenceTransformer("distiluse-base-multilingual-cased-v2")

print("[INFO] Menghasilkan embedding Transformer untuk data train...")
X_train_sbert = sbert_model.encode(list(X_train), show_progress_bar=True)
print("[INFO] Menghasilkan embedding Transformer untuk data test...")
X_test_sbert = sbert_model.encode(list(X_test), show_progress_bar=True)

svm_sbert_clf = LinearSVC(random_state=RANDOM_STATE)
svm_sbert_clf.fit(X_train_sbert, y_train)

y_pred_sbert_svm = svm_sbert_clf.predict(X_test_sbert)

print("=== Percobaan 4: Transformer (SBERT) + Linear SVM ===")
print("Accuracy:", accuracy_score(y_test, y_pred_sbert_svm))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_sbert_svm, digits=4))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_sbert_svm))